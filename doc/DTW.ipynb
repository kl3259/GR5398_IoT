{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Time Warping\n",
    "* 1NN + bespoke distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kangshuoli/Documents/VScode_workspace/GR5398/doc'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import sklearn\n",
    "from glob import glob\n",
    "from tqdm import tqdm # show progress bar\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import math\n",
    "import sys # for sys.float_info.epsilon\n",
    "from numba import njit # speed up numpy calculation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the optimal distance in a recursion fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def DTW(a, b, MTSC = True, method = \"dependent\"):\n",
    "    '''\n",
    "    Input: \n",
    "    a -> time seires m * d numpy array, \n",
    "    b -> time series m * d numpy array, \n",
    "    MTSC -> default is multivariate time series, \n",
    "    method: use `dependent` warping (DTWd) by default, also can use `independent`\n",
    "\n",
    "    Output:\n",
    "    optimal distance\n",
    "    '''\n",
    "    if a.shape[0] != b.shape[0]:\n",
    "        raise ValueError(\"Time length are not the same!\")\n",
    "    if not MTSC:\n",
    "        raise ValueError(\"Input should be MTS!\")\n",
    "    m = a.shape[0] # number of time steps\n",
    "    d = a.shape[1]\n",
    "    assert a.shape[1] == b.shape[1]\n",
    "    M = np.zeros((m,m)) # initialize dependent distance matrix M\n",
    "    M_I = np.zeros((d,m,m)) # initialize independent idstance matrix M_I for each dimension\n",
    "    dp = np.zeros((m,m)) # define dp table -> DTW\n",
    "    if method == \"dependent\": # calculate distance\n",
    "        for i in range(m):\n",
    "            for j in range(i, m):\n",
    "                a_vec_i = a[i,:]\n",
    "                b_vec_j = b[j,:]\n",
    "                diff_vec = a_vec_i - b_vec_j\n",
    "                M[i,j] = np.dot(diff_vec.T, diff_vec)\n",
    "                M[j,i] = M[i,j]\n",
    "        # find the warping path\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                # base case\n",
    "                if i == 0 and j == 0:\n",
    "                    dp[i,j] = M[i,j]\n",
    "                    continue\n",
    "                elif i == 0 and j != 0:\n",
    "                    dp[i,j] = M[i,j] + dp[i,j-1]\n",
    "                    continue\n",
    "                elif i != 0 and j == 0:\n",
    "                    dp[i,j] = M[i,j] + dp[i-1, j]\n",
    "                    continue\n",
    "                dp[i,j] = M[i,j] + min(dp[i-1, j], dp[i,j-1], dp[i-1,j-1])\n",
    "        return dp[m-1,m-1]\n",
    "    elif method == \"independent\":\n",
    "        for k in range(d): # calculate distance independently\n",
    "            for i in range(m):\n",
    "                for j in range(i, m):\n",
    "                    a_i = a[i,k]\n",
    "                    b_j = b[j,k]\n",
    "                    diff = (a_i - b_j) ** 2\n",
    "                    M_I[k,i,j] = diff\n",
    "                    M_I[k,j,i] = M_I[k,i,j]\n",
    "        # find the warping path\n",
    "        dp_I = np.zeros((d,m,m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                # base case\n",
    "                if i == 0 and j == 0:\n",
    "                    dp_I[:,i,j] = M_I[:,i,j]\n",
    "                    continue\n",
    "                elif i == 0 and j != 0:\n",
    "                    dp_I[:,i,j] = M_I[:,i,j] + dp_I[:,i,j-1]\n",
    "                    continue\n",
    "                elif i != 0 and j == 0:\n",
    "                    dp_I[:,i,j] = M_I[:,i,j] + dp_I[:,i-1, j]\n",
    "                    continue\n",
    "                for k in range(d):\n",
    "                    dp_I[k,i,j] = M_I[k,i,j] + min(dp_I[k,i-1,j], dp_I[k,i,j-1], dp_I[k,i-1,j-1])\n",
    "        dp[i,j] = np.sum(dp_I[:,i,j], axis = 0)\n",
    "        return dp[m-1,m-1]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method!\")\n",
    "\n",
    "\n",
    "def find_scores(mts_train, label_train):\n",
    "    '''\n",
    "    Input:\n",
    "    mts_train: traning set of multivariate time series\n",
    "    label_train: labels for training set\n",
    "\n",
    "    Use cross validation\n",
    "\n",
    "    Output:\n",
    "    threshold: adjusted threshold\n",
    "    '''\n",
    "    nn_label_D, nn_label_I = np.empty(mts_train.shape[0]), np.empty(mts_train.shape[0])\n",
    "    S_dSuccess, S_iSuccess = [], []\n",
    "    S = np.empty(mts_train.shape[0])\n",
    "    print(\"Finding Scores:\")\n",
    "    for i in tqdm(range(mts_train.shape[0])):\n",
    "        curr_label = label_train[i]\n",
    "        curr_min_distance_I, curr_min_distance_D = math.inf, math.inf\n",
    "        curr_index_list = list(range(0,mts_train.shape[0]))\n",
    "        curr_index_list.remove(i)\n",
    "        temp_mts_train = mts_train[curr_index_list,:]\n",
    "        temp_label_train = label_train[curr_index_list]\n",
    "        for j in range(temp_mts_train.shape[0]):\n",
    "            curr_distance_D = DTW(mts_train[i,:,:], temp_mts_train[j,:,:], \"dependent\")\n",
    "            curr_distance_I = DTW(mts_train[i,:,:], temp_mts_train[j,:,:], \"independent\")\n",
    "            if curr_distance_D <= curr_min_distance_D:\n",
    "                curr_min_distance_D = curr_distance_D\n",
    "                nn_label_D[j] = temp_label_train[j]\n",
    "            if curr_distance_I <= curr_min_distance_I:\n",
    "                curr_min_distance_I = curr_distance_I\n",
    "                nn_label_I[j] = temp_label_train[j]\n",
    "        curr_score = curr_min_distance_D / (curr_min_distance_I + sys.float_info.epsilon)\n",
    "        S[i] = curr_score\n",
    "        if nn_label_D[i] == curr_label and nn_label_I[i] != curr_label: # dSuccess\n",
    "            S_dSuccess.append(curr_score)\n",
    "        if nn_label_D[i] != curr_label and nn_label_I[i] == curr_label: # iSuccess\n",
    "            S_iSuccess.append(curr_score)\n",
    "        sleep(0.01)\n",
    "    print(\"Done!\")\n",
    "    sleep(0.3)\n",
    "    return S, S_iSuccess, S_dSuccess\n",
    "\n",
    "\n",
    "def learn_threshold(mts_train, label_train):\n",
    "    '''\n",
    "    Input:\n",
    "    mts_train: traning set of multivariate time series\n",
    "    label_train: labels for training set\n",
    "\n",
    "    Use cross validation\n",
    "\n",
    "    Output:\n",
    "    threshold: adjusted threshold\n",
    "    '''\n",
    "    S, S_iSuccess, S_dSuccess = find_scores(mts_train, label_train)\n",
    "    print(\"Learning Threshold\")\n",
    "    if len(S_iSuccess) == 0 and len(S_dSuccess) == 0:\n",
    "        threshold = 1\n",
    "    elif len(S_iSuccess) == 0:\n",
    "        threshold = max(S_dSuccess)\n",
    "    elif len(S_dSuccess) == 0:\n",
    "        threshold = max(S_iSuccess)\n",
    "    else:\n",
    "        # reconstruct the data: label iSuccess -> 0, dSuccess -> 1\n",
    "        data = np.concatenate((np.asarray(S_iSuccess), np.asarray(S_dSuccess)))\n",
    "        label = np.concatenate((np.ones(len(S_iSuccess)), np.zeros(len(S_dSuccess))))\n",
    "        dec_tree = DecisionTreeClassifier(\n",
    "            max_depth = 1, \n",
    "            max_leaf_nodes = 2, \n",
    "            random_state = 42, \n",
    "            max_features = 1, \n",
    "            criterion = \"entropy\", \n",
    "            splitter = \"best\"\n",
    "        )\n",
    "        dec_tree.fit(data, label)\n",
    "        threshold = dec_tree.tree_.threshold[0]\n",
    "    print(\"Done!\")\n",
    "    return threshold\n",
    "\n",
    "\n",
    "def DTW_adaptive(a, b, threshold):\n",
    "    '''\n",
    "    Input:\n",
    "    a -> time seires m * d numpy array, \n",
    "    b -> time series m * d numpy array, \n",
    "    threshold -> adjusted threshold\n",
    "    \n",
    "    Output:\n",
    "    adaptive distance\n",
    "    '''\n",
    "    if a.shape[0] != b.shape[0]:\n",
    "        raise ValueError(\"Time length are not the same!\")\n",
    "    m = a.shape[0] # number of time steps\n",
    "    d = a.shape[1]\n",
    "    assert a.shape[1] == b.shape[1]\n",
    "    # dependent\n",
    "    DTW_D = DTW(a, b, MTSC = True, method = \"dependent\")\n",
    "    # independent\n",
    "    DTW_I = DTW(a, b, MTSC = True, method = \"independent\")\n",
    "    # adaptive\n",
    "    S = DTW_D / (DTW_I + sys.float_info.epsilon)\n",
    "    # thesis got wrong version, this code is correct instead\n",
    "    if S > threshold:\n",
    "        return DTW_I\n",
    "    else:\n",
    "        return DTW_D\n",
    "\n",
    "\n",
    "def NN_DTW(mts_train, mts_test, label_train, index = label_test.index, method = \"dependent\"):\n",
    "    '''\n",
    "    Input:\n",
    "    mts_train: traning set of multivariate time series\n",
    "    mts_test: test set of multivariate time series\n",
    "    label_train: labels for training set\n",
    "\n",
    "    Use 1NN classifier\n",
    "\n",
    "    Output:\n",
    "    label_pred: list of label predicted by the 1NN\n",
    "    '''\n",
    "    label_pred = []\n",
    "    if method != \"adaptive\":\n",
    "        for i in tqdm(range(mts_test.shape[0])): # for each test data\n",
    "            curr_min_distance = math.inf\n",
    "            min_distance_label = None\n",
    "            for j in range(mts_train.shape[0]): # for each training data\n",
    "                curr_distance = DTW(mts_test[i,:,:], mts_train[j,:,:], method)\n",
    "                if curr_distance <= curr_min_distance:\n",
    "                    curr_min_distance = curr_distance\n",
    "                    min_distance_label = label_train[j]\n",
    "            label_pred.append(min_distance_label)\n",
    "            sleep(0.01)\n",
    "        sleep(0.3)\n",
    "    else:\n",
    "        # determine the threshold\n",
    "        threshold = learn_threshold(mts_train, label_train)\n",
    "        print(\"Classifying:\")\n",
    "        for i in tqdm(range(mts_test.shape[0])): # for each test data\n",
    "            curr_min_distance = math.inf\n",
    "            min_distance_label = None\n",
    "            for j in range(mts_train.shape[0]): # for each training data\n",
    "                curr_distance =  DTW_adaptive(mts_test[i,:,:], mts_train[j,:,:], threshold)\n",
    "                if curr_distance <= curr_min_distance:\n",
    "                    curr_min_distance = curr_distance\n",
    "                    min_distance_label = label_train[j]\n",
    "            label_pred.append(min_distance_label)\n",
    "            sleep(0.01)\n",
    "        sleep(0.3)\n",
    "\n",
    "    return pd.Series(label_pred, index = index)\n",
    "\n",
    "\n",
    "def NN_DTW(mts_train, mts_test, label_train, index = label_test.index, method = \"dependent\"):\n",
    "    '''\n",
    "    Input:\n",
    "    mts_train: traning set of multivariate time series\n",
    "    mts_test: test set of multivariate time series\n",
    "    label_train: labels for training set\n",
    "\n",
    "    Use 1NN classifier\n",
    "\n",
    "    Output:\n",
    "    label_pred: list of label predicted by the 1NN\n",
    "    '''\n",
    "    label_pred = []\n",
    "    if method != \"adaptive\":\n",
    "        for i in tqdm(range(mts_test.shape[0])): # for each test data\n",
    "            curr_min_distance = math.inf\n",
    "            min_distance_label = None\n",
    "            for j in range(mts_train.shape[0]): # for each training data\n",
    "                curr_distance = DTW(mts_test[i,:,:], mts_train[j,:,:], method)\n",
    "                if curr_distance <= curr_min_distance:\n",
    "                    curr_min_distance = curr_distance\n",
    "                    min_distance_label = label_train[j]\n",
    "            label_pred.append(min_distance_label)\n",
    "            sleep(0.01)\n",
    "        sleep(0.3)\n",
    "    else:\n",
    "        # determine the threshold\n",
    "        threshold = learn_threshold(mts_train, label_train)\n",
    "        print(\"Classifying:\")\n",
    "        for i in tqdm(range(mts_test.shape[0])): # for each test data\n",
    "            curr_min_distance = math.inf\n",
    "            min_distance_label = None\n",
    "            for j in range(mts_train.shape[0]): # for each training data\n",
    "                curr_distance =  DTW_adaptive(mts_test[i,:,:], mts_train[j,:,:], threshold)\n",
    "                if curr_distance <= curr_min_distance:\n",
    "                    curr_min_distance = curr_distance\n",
    "                    min_distance_label = label_train[j]\n",
    "            label_pred.append(min_distance_label)\n",
    "            sleep(0.01)\n",
    "        sleep(0.3)\n",
    "\n",
    "    return pd.Series(label_pred, index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Usage:\n",
    "mts_train_np = np.asarray(mts_train)\n",
    "mts_test_np = np.asarray(mts_test)\n",
    "label_train_np = np.asarray(label_train)\n",
    "label_test_np = np.asarray(label_test)\n",
    "\n",
    "label_pred = NN_DTW(mts_train_np, mts_test_np, label_train_np, method = \"dependent\")\n",
    "label_pred = NN_DTW(mts_train_np, mts_test_np, label_train_np, method = \"adaptive\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf4b1ea9e44270800601995b24955b9e2e1146cee5677c8b3eb4516f39ae2322"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
