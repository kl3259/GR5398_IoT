{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction by interpolation\n",
    "* Get full keypoints by Videopose3D\n",
    "* Interpolate to 100 time steps\n",
    "* 951 non-duplicated videos\n",
    "* Transform keypoints in ubiquitous scale (1920 * 1080 -> 1280 * 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xmode plain\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "os.listdir('/content/drive/My Drive/IOT Classification Challenge/')\n",
    "\n",
    "PATH = '/content/drive/My Drive/IOT Classification Challenge/combined_dataset/'\n",
    "DATASET = PATH\n",
    "\n",
    "path_features = '/content/drive/My Drive/IOT Classification Challenge/Featurized_dataset/'\n",
    "feature_dirs = [y for x in os.walk(path_features) for y in glob(os.path.join(x[0], \"*.mp4.npz\"))]\n",
    "assert len(feature_dirs) == 977\n",
    "\n",
    "def extract_trajectories(keypoints, dim = 2, with_index = False):\n",
    "    trajectory = []\n",
    "    index = []\n",
    "    for i, (_,k) in enumerate(keypoints):\n",
    "        if len(k) != 0: # removes data where nothing is happening\n",
    "            index.append(i)\n",
    "            three_d_point = k[0,[0,1,3],:] \n",
    "            two_d_point = k[0,[0,1],:] # only x and y, no confidence\n",
    "            if dim == 2:\n",
    "                trajectory.append(two_d_point)\n",
    "            elif dim == 3:\n",
    "                trajectory.append(three_d_point)\n",
    "    if len(trajectory) == 0:\n",
    "        return [] # ignore vdieos w/o any trajectory extracted\n",
    "    if with_index:\n",
    "        return np.stack(trajectory), index\n",
    "    else:\n",
    "        return np.stack(trajectory)\n",
    "\n",
    "\n",
    "def traj_interp(traj, n_frames=100): # interpolation\n",
    "    n_samples = traj.shape[0]\n",
    "    if n_samples == 0:\n",
    "        raise ValueError(\"trajectories of length 0!!\")\n",
    "    result = np.empty((n_frames, 2, 17))\n",
    "    traj = np.asarray(traj)\n",
    "    dest_x = np.linspace(0, 100, n_frames)\n",
    "    src_x = np.linspace(0, 100, n_samples)\n",
    "    for i in range(2):\n",
    "        for j in range(17):\n",
    "            result[:, i, j] = np.interp(\n",
    "                dest_x,\n",
    "                src_x,\n",
    "                traj[:, i, j]\n",
    "            )\n",
    "    return result.reshape(-1)\n",
    "\n",
    "def get_full_feature_data(feature_dirs, transform=None, **kwargs):\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_id_list = []\n",
    "    label_encoder = {'no_interaction': 0, 'open_close_fridge': 1,\n",
    "                     'put_back_item': 2, 'screen_interaction': 3, 'take_out_item': 4}\n",
    "\n",
    "    for path in feature_dirs:\n",
    "        video_id = re.search('(?<=[0-9]\\_)[0-9]+?\\_[0-9](?=\\.mp4|\\s2\\.mp4)', path).group(0)\n",
    "        label = re.search('(?<=Featurized_dataset\\/).+(?=\\_[0-9]+\\_[0-9]+\\_.*?\\.mp4\\.npz)', path).group(0)\n",
    "        d = np.load(path, allow_pickle=True)\n",
    "        traj = extract_trajectories(d['keypoints'], with_index=False)\n",
    "        if transform and len(traj) != 0:\n",
    "            traj = transform(traj, **kwargs)\n",
    "        if len(traj) != 0 and video_id not in video_id_list:\n",
    "            video_id_list.append(video_id)\n",
    "            labels.append(label_encoder.get(label, None))\n",
    "            features.append(traj)\n",
    "\n",
    "    return video_id_list, features, np.stack(labels)\n",
    "\n",
    "video_id_list, feature_df, label_df = get_full_feature_data(feature_dirs, transform = traj_interp) # feature_dirs should be the npz list\n",
    "feature_df = pd.DataFrame(feature_df, index = video_id_list) # (971,3400) -> remove duplication (951,3400)\n",
    "label_df = pd.Series(label_df, index = video_id_list) # (971,) -> remove duplication (951,)\n",
    "\n",
    "# rescale the key points according to resolutions\n",
    "for i in range(feature_df.shape[0]):\n",
    "    if np.max(feature_df.iloc[i,:]) > 1280 or np.max(feature_df.iloc[i,list(range(17,34))]) > 720:\n",
    "        feature_df.iloc[i,:] = feature_df.iloc[i,:] / 1.5\n",
    "\n",
    "# save result\n",
    "feature_df.to_csv(\n",
    "    \"/content/drive/MyDrive/IOT Classification Challenge/feature_df_951.csv\", \n",
    "    header = True\n",
    ")\n",
    "label_df.to_csv(\n",
    "    \"/content/drive/MyDrive/IOT Classification Challenge/label_df_951.csv\", \n",
    "    header = True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
